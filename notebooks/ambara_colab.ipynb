{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambara — Colab Runner\n",
    "\n",
    "Automated notebook for running **ingest** (extract + sync) and **iterate**\n",
    "(export + train + re-draft) on Colab with a free GPU.\n",
    "\n",
    "**Usage:** Fill in the configuration cell below, then **Runtime > Run All**.\n",
    "\n",
    "- Clips are pulled from / pushed to Supabase automatically — no manual uploads.\n",
    "- Trained models are pushed to HuggingFace Hub — no Google Drive needed.\n",
    "- Google Drive is only used for the `.env` file (Supabase credentials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Google Drive (only for .env) ----\n",
    "DRIVE_ROOT = \"ambara\"\n",
    "\n",
    "# ---- Repository ----\n",
    "REPO_URL = \"https://github.com/ny-randriantsarafara/ny-feoko.git\"\n",
    "REPO_BRANCH = \"main\"\n",
    "\n",
    "# ---- HuggingFace ----\n",
    "HF_TOKEN = \"\"  # Write token — required for --push-to-hub\n",
    "\n",
    "# ---- Ingest: download + extract + sync (set False to skip) ----\n",
    "INGEST_ENABLED = False\n",
    "INGEST_INPUT = \"https://youtube.com/watch?v=...\"  # YouTube URL or Drive file path\n",
    "INGEST_LABEL = \"my-recording\"\n",
    "INGEST_WHISPER_HF = \"\"  # HuggingFace model ID for transcription (leave empty for stock Whisper)\n",
    "\n",
    "# ---- Iterate: export + train + re-draft (set False to skip) ----\n",
    "ITERATE_ENABLED = True\n",
    "ITERATE_LABEL = \"\"  # Run label in Supabase (from ingest)\n",
    "ITERATE_BASE_MODEL = \"openai/whisper-small\"\n",
    "ITERATE_EPOCHS = 10\n",
    "ITERATE_BATCH_SIZE = 4\n",
    "ITERATE_LR = 1e-5\n",
    "ITERATE_PUSH_TO_HUB = \"\"  # HuggingFace repo ID — strongly recommended on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Mounts Drive (for `.env` only), clones the repo, and installs dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "DRIVE_MOUNT = Path(\"/content/drive\")\n",
    "DRIVE_BASE = DRIVE_MOUNT / \"MyDrive\" / DRIVE_ROOT\n",
    "REPO_DIR = Path(\"/content/ny-feoko\")\n",
    "\n",
    "# ---- Mount Google Drive (for .env) ----\n",
    "if not (DRIVE_MOUNT / \"MyDrive\").exists():\n",
    "    drive.mount(str(DRIVE_MOUNT))\n",
    "DRIVE_BASE.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Drive mounted at {DRIVE_MOUNT}\")\n",
    "\n",
    "# ---- Clone or update repo ----\n",
    "if REPO_DIR.exists():\n",
    "    subprocess.run(\n",
    "        [\"git\", \"-C\", str(REPO_DIR), \"pull\", \"--ff-only\"],\n",
    "        check=True,\n",
    "    )\n",
    "    print(f\"Repo updated: {REPO_DIR}\")\n",
    "else:\n",
    "    subprocess.run(\n",
    "        [\"git\", \"clone\", \"-b\", REPO_BRANCH, REPO_URL, str(REPO_DIR)],\n",
    "        check=True,\n",
    "    )\n",
    "    print(f\"Repo cloned: {REPO_DIR}\")\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# ---- Symlink .env from Drive (if present) ----\n",
    "env_drive = DRIVE_BASE / \".env\"\n",
    "env_local = REPO_DIR / \".env\"\n",
    "if env_drive.exists():\n",
    "    if env_local.is_symlink() or env_local.exists():\n",
    "        env_local.unlink()\n",
    "    env_local.symlink_to(env_drive)\n",
    "    print(f\"  .env -> {env_drive}\")\n",
    "else:\n",
    "    print(\"WARNING: No .env found on Drive. Place it at My Drive/ambara/.env\")\n",
    "\n",
    "# ---- Python version check ----\n",
    "v = sys.version_info\n",
    "print(f\"\\nPython {v.major}.{v.minor}.{v.micro}\")\n",
    "if v < (3, 10):\n",
    "    print(\"WARNING: This project requires Python >= 3.10.\")\n",
    "\n",
    "# ---- Install dependencies ----\n",
    "subprocess.run([\"make\", \"colab-install\"], check=True, cwd=str(REPO_DIR))\n",
    "\n",
    "# ---- HuggingFace login ----\n",
    "if HF_TOKEN:\n",
    "    from huggingface_hub import login\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"Logged in to HuggingFace Hub.\")\n",
    "\n",
    "# ---- Environment summary ----\n",
    "import torch\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA:    {torch.cuda.is_available()} ({gpu_name})\")\n",
    "print(f\"Repo:    {REPO_DIR}\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest\n",
    "\n",
    "Downloads audio (if URL), extracts speech clips, and syncs everything to\n",
    "Supabase in one shot. Skip this if you already ingested locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INGEST_ENABLED:\n",
    "    print(\"Ingest skipped (INGEST_ENABLED = False).\")\n",
    "else:\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"pipeline.cli\", \"ingest\",\n",
    "        INGEST_INPUT,\n",
    "        \"--device\", \"cuda\",\n",
    "        \"--verbose\",\n",
    "    ]\n",
    "    if INGEST_LABEL:\n",
    "        cmd += [\"--label\", INGEST_LABEL]\n",
    "    if INGEST_WHISPER_HF:\n",
    "        cmd += [\"--whisper-hf\", INGEST_WHISPER_HF]\n",
    "\n",
    "    print(f\"Running: {' '.join(cmd)}\")\n",
    "    subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate\n",
    "\n",
    "Exports corrected clips from Supabase, fine-tunes Whisper, and re-drafts\n",
    "pending clips — all in one command. Clips are downloaded from Supabase\n",
    "Storage automatically (no manual upload needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ITERATE_ENABLED:\n",
    "    print(\"Iterate skipped (ITERATE_ENABLED = False).\")\n",
    "elif not ITERATE_LABEL:\n",
    "    print(\"ERROR: Set ITERATE_LABEL to the run label from ingest.\")\n",
    "else:\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"pipeline.cli\", \"iterate\",\n",
    "        \"--label\", ITERATE_LABEL,\n",
    "        \"--device\", \"cuda\",\n",
    "        \"--base-model\", ITERATE_BASE_MODEL,\n",
    "        \"--epochs\", str(ITERATE_EPOCHS),\n",
    "        \"--batch-size\", str(ITERATE_BATCH_SIZE),\n",
    "        \"--lr\", str(ITERATE_LR),\n",
    "    ]\n",
    "    if ITERATE_PUSH_TO_HUB:\n",
    "        cmd += [\"--push-to-hub\", ITERATE_PUSH_TO_HUB]\n",
    "\n",
    "    print(f\"Running: {' '.join(cmd)}\")\n",
    "    subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Summary of what happened and suggested next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(f\"{'=' * 50}\")\n",
    "print(\"Results\")\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "model_dir = Path(\"models/whisper-mg-v1/model\")\n",
    "if model_dir.exists():\n",
    "    size_mb = sum(f.stat().st_size for f in model_dir.rglob(\"*\") if f.is_file()) / (1024 * 1024)\n",
    "    print(f\"\\nTrained model: {model_dir} ({size_mb:.0f} MB)\")\n",
    "\n",
    "if ITERATE_PUSH_TO_HUB:\n",
    "    print(f\"  HuggingFace: https://huggingface.co/{ITERATE_PUSH_TO_HUB}\")\n",
    "\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Open the transcript editor: ./ambara editor\")\n",
    "print(f\"  2. Correct the improved drafts\")\n",
    "print(f\"  3. Run this notebook again to train on the new corrections\")\n",
    "if ITERATE_PUSH_TO_HUB:\n",
    "    print(f\"\\nUse the model locally:\")\n",
    "    print(f\"  ./ambara extract -i audio.wav -o data/output/ --device mps \\\\\")\n",
    "    print(f\"      --whisper-hf {ITERATE_PUSH_TO_HUB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ambara_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
