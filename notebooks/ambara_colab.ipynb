{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ambara — Colab Runner\n",
        "\n",
        "Automated notebook for running **clip extraction** and **ASR training** on\n",
        "Colab with Google Drive persistence.\n",
        "\n",
        "**Usage:** Edit the configuration cell below, then **Runtime > Run All**.\n",
        "\n",
        "- Repo is cloned to the VM for fast I/O.\n",
        "- `data/` and `models/` are symlinked to Google Drive so they persist across sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Google Drive ----\n",
        "DRIVE_ROOT = \"ambara\"\n",
        "\n",
        "# ---- Repository ----\n",
        "REPO_URL = \"https://github.com/ny-randriantsarafara/ny-feoko.git\"\n",
        "REPO_BRANCH = \"main\"\n",
        "\n",
        "# ---- HuggingFace (leave empty to skip login) ----\n",
        "HF_TOKEN = \"\"\n",
        "\n",
        "# ---- Clip Extraction (set EXTRACT_ENABLED = False to skip) ----\n",
        "EXTRACT_ENABLED = True\n",
        "EXTRACT_INPUT = \"data/input/my-recording.wav\"\n",
        "EXTRACT_WHISPER_MODEL = \"small\"\n",
        "EXTRACT_WHISPER_HF = \"\"  # HuggingFace model ID — overrides EXTRACT_WHISPER_MODEL\n",
        "EXTRACT_VAD_THRESHOLD = 0.35\n",
        "EXTRACT_SPEECH_THRESHOLD = 0.35\n",
        "EXTRACT_LABEL = \"\"\n",
        "\n",
        "# ---- ASR Training (set TRAIN_ENABLED = False to skip) ----\n",
        "TRAIN_ENABLED = True\n",
        "TRAIN_DATASET = \"data/training/my-dataset\"\n",
        "TRAIN_BASE_MODEL = \"openai/whisper-small\"\n",
        "TRAIN_OUTPUT_DIR = \"models/whisper-mg-v1\"\n",
        "TRAIN_EPOCHS = 10\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "TRAIN_LR = 1e-5\n",
        "TRAIN_PUSH_TO_HUB = \"\"  # HuggingFace repo ID — leave empty to skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Mounts Drive, clones the repo, creates symlinks for `data/` and `models/`,\n",
        "and installs Python dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      9\u001b[39m DRIVE_MOUNT = Path(\u001b[33m\"\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m DRIVE_BASE = DRIVE_MOUNT / \u001b[33m\"\u001b[39m\u001b[33mMyDrive\u001b[39m\u001b[33m\"\u001b[39m / DRIVE_ROOT\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "DRIVE_MOUNT = Path(\"/content/drive\")\n",
        "DRIVE_BASE = DRIVE_MOUNT / \"MyDrive\" / DRIVE_ROOT\n",
        "REPO_DIR = Path(\"/content/ny-feoko\")\n",
        "\n",
        "# ---- Mount Google Drive ----\n",
        "if not (DRIVE_MOUNT / \"MyDrive\").exists():\n",
        "    drive.mount(str(DRIVE_MOUNT))\n",
        "print(f\"Drive mounted at {DRIVE_MOUNT}\")\n",
        "\n",
        "# ---- Create Drive directories ----\n",
        "for subdir in [\"data/input\", \"data/output\", \"data/training\", \"models\"]:\n",
        "    (DRIVE_BASE / subdir).mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Drive root: {DRIVE_BASE}\")\n",
        "\n",
        "# ---- Clone or update repo ----\n",
        "if REPO_DIR.exists():\n",
        "    subprocess.run(\n",
        "        [\"git\", \"-C\", str(REPO_DIR), \"pull\", \"--ff-only\"],\n",
        "        check=True,\n",
        "    )\n",
        "    print(f\"Repo updated: {REPO_DIR}\")\n",
        "else:\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"-b\", REPO_BRANCH, REPO_URL, str(REPO_DIR)],\n",
        "        check=True,\n",
        "    )\n",
        "    print(f\"Repo cloned: {REPO_DIR}\")\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# ---- Symlink data/ and models/ to Drive ----\n",
        "for name in [\"data\", \"models\"]:\n",
        "    link = REPO_DIR / name\n",
        "    target = DRIVE_BASE / name\n",
        "    if link.is_symlink():\n",
        "        link.unlink()\n",
        "    elif link.is_dir():\n",
        "        shutil.rmtree(link)\n",
        "    link.symlink_to(target)\n",
        "    print(f\"  {name}/ -> {target}\")\n",
        "\n",
        "# ---- Symlink .env from Drive (if present) ----\n",
        "env_drive = DRIVE_BASE / \".env\"\n",
        "env_local = REPO_DIR / \".env\"\n",
        "if env_drive.exists():\n",
        "    if env_local.is_symlink() or env_local.exists():\n",
        "        env_local.unlink()\n",
        "    env_local.symlink_to(env_drive)\n",
        "    print(f\"  .env -> {env_drive}\")\n",
        "\n",
        "# ---- Python version check ----\n",
        "v = sys.version_info\n",
        "print(f\"\\nPython {v.major}.{v.minor}.{v.micro}\")\n",
        "if v < (3, 10):\n",
        "    print(\"WARNING: This project requires Python >= 3.10.\")\n",
        "\n",
        "# ---- Install dependencies ----\n",
        "subprocess.run([\"make\", \"colab-install\"], check=True, cwd=str(REPO_DIR))\n",
        "\n",
        "# ---- HuggingFace login ----\n",
        "if HF_TOKEN:\n",
        "    from huggingface_hub import login\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Logged in to HuggingFace Hub.\")\n",
        "\n",
        "# ---- Environment summary ----\n",
        "import torch\n",
        "\n",
        "gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"\n",
        "print(f\"\\n{'=' * 50}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA:    {torch.cuda.is_available()} ({gpu_name})\")\n",
        "print(f\"Drive:   {DRIVE_BASE}\")\n",
        "print(f\"Repo:    {REPO_DIR}\")\n",
        "print(f\"{'=' * 50}\")\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clip Extraction\n",
        "\n",
        "Runs the full pipeline: **VAD → classify → transcribe → write clips**.\n",
        "\n",
        "Input file must exist at the configured path on Drive (e.g.\n",
        "`My Drive/ambara/data/input/my-recording.wav`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not EXTRACT_ENABLED:\n",
        "    print(\"Clip extraction skipped (EXTRACT_ENABLED = False).\")\n",
        "else:\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"clip_extraction.cli\", \"run\",\n",
        "        \"--input\", EXTRACT_INPUT,\n",
        "        \"--output\", \"data/output\",\n",
        "        \"--device\", \"cuda\",\n",
        "        \"--vad-threshold\", str(EXTRACT_VAD_THRESHOLD),\n",
        "        \"--speech-threshold\", str(EXTRACT_SPEECH_THRESHOLD),\n",
        "        \"--verbose\",\n",
        "    ]\n",
        "    if EXTRACT_WHISPER_HF:\n",
        "        cmd += [\"--whisper-hf\", EXTRACT_WHISPER_HF]\n",
        "    else:\n",
        "        cmd += [\"--whisper-model\", EXTRACT_WHISPER_MODEL]\n",
        "    if EXTRACT_LABEL:\n",
        "        cmd += [\"--label\", EXTRACT_LABEL]\n",
        "\n",
        "    print(f\"Running: {' '.join(cmd)}\")\n",
        "    subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ASR Training\n",
        "\n",
        "Fine-tunes Whisper on the configured training dataset. The dataset must\n",
        "already exist on Drive (exported locally via `./ambara export-training`,\n",
        "then uploaded to `My Drive/ambara/data/training/<dataset>/`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not TRAIN_ENABLED:\n",
        "    print(\"ASR training skipped (TRAIN_ENABLED = False).\")\n",
        "else:\n",
        "    cmd = [\n",
        "        \"python\", \"-m\", \"asr_training.cli\", \"train\",\n",
        "        \"--data-dir\", TRAIN_DATASET,\n",
        "        \"--output-dir\", TRAIN_OUTPUT_DIR,\n",
        "        \"--device\", \"cuda\",\n",
        "        \"--base-model\", TRAIN_BASE_MODEL,\n",
        "        \"--epochs\", str(TRAIN_EPOCHS),\n",
        "        \"--batch-size\", str(TRAIN_BATCH_SIZE),\n",
        "        \"--lr\", str(TRAIN_LR),\n",
        "    ]\n",
        "    if TRAIN_PUSH_TO_HUB:\n",
        "        cmd += [\"--push-to-hub\", TRAIN_PUSH_TO_HUB]\n",
        "\n",
        "    print(f\"Running: {' '.join(cmd)}\")\n",
        "    subprocess.run(cmd, check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "Shows extraction and training outputs, Drive usage, and suggested next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{'=' * 50}\")\n",
        "print(\"Results\")\n",
        "print(f\"{'=' * 50}\")\n",
        "\n",
        "# ---- Extraction output ----\n",
        "output_dir = REPO_DIR / \"data\" / \"output\"\n",
        "if output_dir.exists():\n",
        "    runs = sorted(d for d in output_dir.iterdir() if d.is_dir())\n",
        "    if runs:\n",
        "        latest = runs[-1]\n",
        "        clips_dir = latest / \"clips\"\n",
        "        clip_count = len(list(clips_dir.glob(\"*.wav\"))) if clips_dir.exists() else 0\n",
        "        print(f\"\\nLatest extraction run: {latest.name}\")\n",
        "        print(f\"  Clips extracted: {clip_count}\")\n",
        "\n",
        "# ---- Training output ----\n",
        "model_dir = REPO_DIR / TRAIN_OUTPUT_DIR / \"model\"\n",
        "if model_dir.exists():\n",
        "    size_mb = sum(f.stat().st_size for f in model_dir.rglob(\"*\") if f.is_file()) / (1024 * 1024)\n",
        "    print(f\"\\nTrained model: {model_dir}\")\n",
        "    print(f\"  Size: {size_mb:.0f} MB\")\n",
        "    print(f\"  Persisted at: {DRIVE_BASE / TRAIN_OUTPUT_DIR / 'model'}\")\n",
        "\n",
        "if TRAIN_PUSH_TO_HUB:\n",
        "    print(f\"  HuggingFace: https://huggingface.co/{TRAIN_PUSH_TO_HUB}\")\n",
        "\n",
        "# ---- Drive usage ----\n",
        "print(f\"\\nDrive usage ({DRIVE_BASE}):\")\n",
        "for subdir in [\"data/input\", \"data/output\", \"data/training\", \"models\"]:\n",
        "    p = DRIVE_BASE / subdir\n",
        "    if p.exists():\n",
        "        total = sum(f.stat().st_size for f in p.rglob(\"*\") if f.is_file())\n",
        "        print(f\"  {subdir}: {total / (1024 * 1024):.0f} MB\")\n",
        "\n",
        "# ---- Next steps ----\n",
        "next_model = TRAIN_PUSH_TO_HUB if TRAIN_PUSH_TO_HUB else f\"{TRAIN_OUTPUT_DIR}/model\"\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"  ./ambara re-draft --model {next_model} \\\\\")\n",
        "print(f\"      -d data/output/<run-dir> --label <run-label>\")\n",
        "if TRAIN_PUSH_TO_HUB:\n",
        "    print(f\"  ./ambara extract -i audio.wav -o data/output/ --device mps \\\\\")\n",
        "    print(f\"      --whisper-hf {TRAIN_PUSH_TO_HUB}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ambara_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
